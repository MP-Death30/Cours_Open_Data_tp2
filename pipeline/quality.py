"""Module de scoring et rapport de qualitÃ©."""
import pandas as pd
from datetime import datetime
from pathlib import Path
from litellm import completion, AuthenticationError
from dotenv import load_dotenv
import os
import logging

from .config import QUALITY_THRESHOLDS, REPORTS_DIR
from .models import QualityMetrics

load_dotenv()
logger = logging.getLogger(__name__)


class QualityAnalyzer:
    """Analyse et score la qualitÃ© des donnÃ©es."""
    
    def __init__(self, df: pd.DataFrame):
        self.df = df
        self.metrics = None
    
    def calculate_completeness(self) -> float:
        """Calcule le score de complÃ©tude (% de valeurs non-nulles)."""
        total_cells = self.df.size
        non_null_cells = self.df.notna().sum().sum()
        return non_null_cells / total_cells if total_cells > 0 else 0
    
    def count_duplicates(self) -> tuple[int, float]:
        """Compte les doublons en utilisant date et nom de ville."""
        
        # L'ID qui aurait dÃ» Ãªtre unique si les coordonnÃ©es n'Ã©taient pas forcÃ©es
        # Mais nous utilisons les champs textuels pour ignorer la faute de simulation
        id_col = ['date', 'original_city_name'] 
        
        duplicates = self.df.duplicated(subset=id_col).sum()
        pct = duplicates / len(self.df) * 100 if len(self.df) > 0 else 0
        
        return duplicates, pct
    
    def calculate_geocoding_stats(self) -> tuple[float, float]:
        """Calcule les stats de gÃ©ocodage si applicable."""
        if 'geocoding_score' not in self.df.columns:
            return 0, 0
        
        valid_geo = self.df['geocoding_score'].notna() & (self.df['geocoding_score'] > 0)
        success_rate = valid_geo.sum() / len(self.df) * 100 if len(self.df) > 0 else 0
        avg_score = self.df.loc[valid_geo, 'geocoding_score'].mean() if valid_geo.any() else 0
        
        return success_rate, avg_score
    
    def calculate_null_counts(self) -> dict:
        """Compte les valeurs nulles par colonne."""
        return self.df.isnull().sum().to_dict()
    
    def determine_grade(self, completeness: float, duplicates_pct: float, geo_rate: float) -> str:
        """DÃ©termine la note de qualitÃ© globale."""
        score = 0
        
        # ComplÃ©tude (40 points max)
        score += min(completeness * 40, 40)
        
        # Doublons (30 points max)
        if duplicates_pct <= 1:
            score += 30
        elif duplicates_pct <= 5:
            score += 20
        elif duplicates_pct <= 10:
            score += 10
        
        # GÃ©ocodage (30 points max) - si applicable
        if 'geocoding_score' in self.df.columns:
            score += min(geo_rate / 100 * 30, 30)
        else:
            score += 30  # Pas de pÃ©nalitÃ© si pas de gÃ©ocodage
        
        # Note finale
        if score >= 90:
            return 'A'
        elif score >= 75:
            return 'B'
        elif score >= 60:
            return 'C'
        elif score >= 40:
            return 'D'
        else:
            return 'F'
    
    def analyze(self) -> QualityMetrics:
        """Effectue l'analyse complÃ¨te de qualitÃ©."""
        completeness = self.calculate_completeness()
        duplicates, duplicates_pct = self.count_duplicates()
        geo_rate, geo_avg = self.calculate_geocoding_stats()
        null_counts = self.calculate_null_counts()
        
        valid_records = len(self.df) - duplicates
        
        grade = self.determine_grade(completeness, duplicates_pct, geo_rate)
        
        self.metrics = QualityMetrics(
            total_records=len(self.df),
            valid_records=valid_records,
            completeness_score=round(completeness, 3),
            duplicates_count=duplicates,
            duplicates_pct=round(duplicates_pct, 2),
            geocoding_success_rate=round(geo_rate, 2),
            avg_geocoding_score=round(geo_avg, 3),
            null_counts=null_counts,
            quality_grade=grade,
        )
        
        return self.metrics
    
    def generate_ai_recommendations(self) -> str:
        """GÃ©nÃ¨re des recommandations via l'IA avec fallback manuel."""
        if not self.metrics:
            self.analyze()
        
        context = f"""
        Analyse de qualitÃ© d'un dataset MÃ©tÃ©o/GÃ©o :
        - Total: {self.metrics.total_records} enregistrements
        - ComplÃ©tude: {self.metrics.completeness_score * 100:.1f}%
        - Doublons: {self.metrics.duplicates_pct:.1f}%
        - Note: {self.metrics.quality_grade}
        
        Valeurs nulles par colonne:
        {self.metrics.null_counts}
        """
        
        # 1. DÃ‰FINITION DE LA STRATÃ‰GIE DE FALLBACK MANUELLE
        # DÃ©finissez les modÃ¨les dans l'ordre de prioritÃ©
        models_to_try = [
            {"model": "gemini/gemini-2.5-flash-lite"}, # 1. Tentative Gemini (Ã©chouera sans clÃ©)
            {"model": "ollama/mistral", "api_base": os.getenv("OLLAMA_BASE_URL", "http://localhost:11434")} # 2. Tentative Ollama local
        ]
        
        messages = [
            {"role": "system", "content": "Tu es un expert en qualitÃ© des donnÃ©es. Donne des recommandations concrÃ¨tes et actionnables."},
            {"role": "user", "content": f"{context}\n\nQuelles sont tes 5 recommandations prioritaires pour amÃ©liorer ce dataset ?"}
        ]
        
        # 2. BOUCLE DE FALLBACK MANUELLE
        for config in models_to_try:
            model_name = config['model']
            api_base = config.get('api_base')
            
            logger.info(f"Tentative avec le modÃ¨le : {model_name}")
            print(f"ğŸ¤– Tentative IA : {model_name}...")
            
            try:
                # Appelle la fonction completion avec la configuration du modÃ¨le
                response = completion(
                    model=model_name,
                    messages=messages,
                    api_base=api_base # Sera None pour Gemini, la valeur locale pour Ollama
                )
                
                # SuccÃ¨s : Retourne la recommandation
                return response.choices[0].message.content
            
            except AuthenticationError:
                # Si Gemini Ã©choue Ã  cause de la clÃ©, c'est normal, on passe au fallback.
                logger.warning(f"ClÃ© API invalide pour {model_name}. Tentative de fallback.")
                continue
            except Exception as e:
                # GÃ¨re toutes les autres erreurs (connexion, modÃ¨le absent, etc.)
                logger.error(f"Erreur lors de l'appel Ã  {model_name}: {e}")
                continue # Passe au modÃ¨le suivant
        
        # 3. Ã‰chec total
        return "âŒ Recommandations IA indisponibles. Erreur d'authentification ou Ollama n'est pas lancÃ©/configurÃ©."
    
    def generate_report(self, output_name: str = "quality_report") -> Path:
        """GÃ©nÃ¨re un rapport de qualitÃ© complet en Markdown."""
        if not self.metrics:
            self.analyze()
        
        recommendations = self.generate_ai_recommendations()
        
        report = f"""# Rapport de QualitÃ© des DonnÃ©es

**GÃ©nÃ©rÃ© le** : {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}

## ğŸ“Š MÃ©triques Globales

| MÃ©trique | Valeur | Seuil |
|----------|--------|-------|
| **Note globale** | **{self.metrics.quality_grade}** | A-B-C = Acceptable |
| Total enregistrements | {self.metrics.total_records} | - |
| Enregistrements valides | {self.metrics.valid_records} | - |
| ComplÃ©tude | {self.metrics.completeness_score * 100:.1f}% | â‰¥ 70% |
| Doublons | {self.metrics.duplicates_pct:.1f}% | â‰¤ 5% |
| GÃ©ocodage rÃ©ussi | {self.metrics.geocoding_success_rate:.1f}% | â‰¥ 50% |
| Score gÃ©ocodage moyen | {self.metrics.avg_geocoding_score:.2f} | â‰¥ 0.5 |

## ğŸ“‹ Valeurs Manquantes par Colonne

| Colonne | Valeurs nulles | % |
|---------|----------------|---|
"""
        
        for col, count in sorted(self.metrics.null_counts.items(), key=lambda x: x[1], reverse=True):
            pct = count / self.metrics.total_records * 100 if self.metrics.total_records > 0 else 0
            report += f"| {col} | {count} | {pct:.1f}% |\n"
        
        report += f"""

## ğŸ¤– Recommandations IA

{recommendations}

## âœ… Conclusion

{"âœ… **Dataset acceptable** pour l'analyse." if self.metrics.is_acceptable else "âš ï¸ **Dataset nÃ©cessite des corrections** avant utilisation."}

---
*Rapport gÃ©nÃ©rÃ© automatiquement par le pipeline Open Data*
"""
        
        # Sauvegarder
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        filepath = REPORTS_DIR / f"{output_name}_{timestamp}.md"
        filepath.write_text(report, encoding='utf-8')
        
        print(f"ğŸ“„ Rapport sauvegardÃ© : {filepath}")
        return filepath