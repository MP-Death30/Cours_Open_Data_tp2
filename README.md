# ğŸš€ Pipeline Data Engineering : MÃ©tÃ©o & GÃ©odonnÃ©es

![Python Version](https://img.shields.io/badge/python-3.12-blue)
![Status](https://img.shields.io/badge/status-production-green)
![Data Quality](https://img.shields.io/badge/quality-grade%20A-brightgreen)

## ğŸ“‹ Description

Ce projet implÃ©mente un pipeline de donnÃ©es **ETL (Extract, Transform, Load)** robuste et rÃ©silient qui agrÃ¨ge, nettoie et enrichit des donnÃ©es mÃ©tÃ©orologiques et gÃ©ographiques.

Le pipeline est conÃ§u pour Ãªtre **tolÃ©rant aux pannes** et inclut un module d'analyse de qualitÃ© avancÃ© utilisant l'Intelligence Artificielle (Gemini/Ollama) pour gÃ©nÃ©rer des rapports automatisÃ©s.

### ğŸŒŸ FonctionnalitÃ©s ClÃ©s

* **Acquisition Multi-sources :**
    * MÃ©tÃ©o : [Open-Meteo API](https://open-meteo.com/) (PrÃ©visions Ã  7 jours).
    * GÃ©ographie : [API Adresse Data.gouv](https://adresse.data.gouv.fr/) (GÃ©ocodage et normalisation).
* **Architecture RÃ©siliente :**
    * SystÃ¨me de **Retry exponentiel** pour les appels API (gestion des erreurs 429/50x).
    * **Fallback IA** : Bascule automatique de Google Gemini vers Ollama (local) en cas de panne ou quota dÃ©passÃ©.
    * **ExÃ©cution IncrÃ©mentale** : DÃ©tection intelligente des traitements dÃ©jÃ  effectuÃ©s pour Ã©viter la redondance.
* **QualitÃ© des DonnÃ©es :**
    * Calcul automatique de scores (ComplÃ©tude, Doublons, ValiditÃ©).
    * GÃ©nÃ©ration de rapports d'audit en Markdown via LLM.
    * Nettoyage et dÃ©duplication intelligente post-enrichissement.
* **Stockage OptimisÃ© :**
    * DonnÃ©es brutes en JSON (AuditabilitÃ©).
    * DonnÃ©es traitÃ©es en Parquet (Performance analytique).
* **Monitoring :**
    * Logs structurÃ©s (Console + Fichier rotatif).

---

## ğŸ—ï¸ Architecture du Pipeline

Le pipeline suit une architecture sÃ©quentielle modulaire :

1.  **ğŸ“¥ Acquisition (`Fetchers`)** : RÃ©cupÃ©ration des prÃ©visions mÃ©tÃ©o pour une liste de villes cibles.
2.  **ğŸŒ Enrichissement (`Enricher`)** : Correction des coordonnÃ©es et normalisation des noms de villes via gÃ©ocodage.
3.  **ğŸ”§ Transformation (`Transformer`)** : Nettoyage, typage, suppression des doublons et crÃ©ation de colonnes dÃ©rivÃ©es (ex: amplitude thermique).
4.  **ğŸ“Š QualitÃ© (`QualityAnalyzer`)** : Audit statistique et analyse sÃ©mantique par IA.
5.  **ğŸ’¾ Stockage (`Storage`)** : Sauvegarde des artefacts finaux.

---

## ğŸ› ï¸ Installation

### PrÃ©requis

* Python 3.10+
* [UV](https://github.com/astral-sh/uv) (RecommandÃ©) ou Pip.
* (Optionnel) [Ollama](https://ollama.com/) installÃ© localement pour le mode offline/fallback.

### Configuration

1.  **Cloner le dÃ©pÃ´t :**
    ```bash
    git clone [https://github.com/votre-user/cours_open_data_tp2.git](https://github.com/votre-user/cours_open_data_tp2.git)
    cd cours_open_data_tp2
    ```

2.  **Installer les dÃ©pendances :**
    
    *Via UV :*
    ```bash
    uv sync
    ```
    *Via Pip (Standard) :*
    ```bash
    pip install -r requirements.txt
    ```

3.  **Variables d'environnement (.env) :**
    CrÃ©ez un fichier `.env` Ã  la racine :
    ```ini
    # ClÃ© API Google Gemini (Optionnel, le pipeline basculera sur Ollama si absent)
    GEMINI_API_KEY=votre_cle_ici

    # Configuration Ollama (si utilisÃ© en fallback)
    OLLAMA_BASE_URL=http://localhost:11434
    ```

---

## ğŸš€ Utilisation

### Lancer le Pipeline

Pour exÃ©cuter le pipeline complet (Acquisition -> Stockage) :

**Avec UV :**
```bash
uv run python -m pipeline.main
```

**Avec Python standard :**
```bash
# Assurez-vous d'avoir activÃ© votre environnement virtuel
python -m pipeline.main
```

**Options Disponibles**
Le pipeline accepte plusieurs arguments pour personnaliser l'exÃ©cution :

| Option | Raccourci | Description |
| :--- | :--- | :--- |
| `--max-items` | `-m` | Limiter le nombre de villes Ã  traiter (pour les tests) |
| `--skip-enrichment` | `-s` | Sauter l'Ã©tape de gÃ©ocodage |
| `--verbose` | `-v` | Afficher plus de dÃ©tails dans la console |


**Exemples :**
```bash
# Avec UV - Traiter 10 villes en mode verbose
uv run python -m pipeline.main -m 10 -v

# Avec Python standard - Traiter 10 villes en mode verbose
python -m pipeline.main -m 10 -v

# Sauter l'enrichissement gÃ©ographique
python -m pipeline.main -s
```


**VÃ©rifier les DonnÃ©es**
Un script utilitaire est fourni pour inspecter rapidement le fichier Parquet gÃ©nÃ©rÃ© :
```bash
# Avec UV
uv run python check_data.py

# Avec Python standard
python check_data.py
```


## ğŸ“‚ Structure du Projet
```text
ğŸ“ cours_open_data_tp2
â”œâ”€â”€ ğŸ“ data/                  # Stockage des donnÃ©es (ignorÃ© par Git)
â”‚   â”œâ”€â”€ raw/                  # JSON bruts
â”‚   â”œâ”€â”€ processed/            # Parquet finaux
â”‚   â””â”€â”€ reports/              # Rapports de qualitÃ© Markdown
â”œâ”€â”€ ğŸ“ logs/                  # Fichiers de logs rotatifs
â”œâ”€â”€ ğŸ“ pipeline/              # Code source du pipeline
â”‚   â”œâ”€â”€ ğŸ“ fetchers/          # Modules d'acquisition API
â”‚   â”œâ”€â”€ config.py             # Configuration centralisÃ©e
â”‚   â”œâ”€â”€ enricher.py           # Logique de gÃ©ocodage
â”‚   â”œâ”€â”€ main.py               # Point d'entrÃ©e et orchestration
â”‚   â”œâ”€â”€ models.py             # SchÃ©mas de donnÃ©es Pydantic
â”‚   â”œâ”€â”€ quality.py            # Moteur de qualitÃ© et IA
â”‚   â”œâ”€â”€ storage.py            # Gestion I/O
â”‚   â””â”€â”€ transformer.py        # Logique de nettoyage Pandas
â”œâ”€â”€ ğŸ“ tests/                 # Tests unitaires (Pytest)
â”œâ”€â”€ .env                      # Secrets (non versionnÃ©)
â”œâ”€â”€ check_data.py             # Script d'inspection
â”œâ”€â”€ pyproject.toml            # DÃ©pendances et configuration
â””â”€â”€ README.md                 # Ce fichier
```

## ğŸ§ª Tests
Le projet inclut une suite de tests unitaires pour garantir la fiabilitÃ© des transformations et des connexions API.
Lancer les tests :
```bash
# Avec UV
uv run python -m pytest test/ -v

# Avec Python standard
pytest
```

## ğŸ“Š Rapport de QualitÃ©
Le pipeline gÃ©nÃ¨re automatiquement un rapport de qualitÃ© dans `data/reports/meteo_quality_YYYYMMDD.md`.
```text
Exemple de contenu :
markdownNote de QualitÃ© : A

MÃ©triques :
- ComplÃ©tude : 100.0%
- Doublons : 0.0%

Recommandations IA :
1. Les donnÃ©es sont propres et prÃªtes pour l'analyse.
2. La couverture gÃ©ographique est cohÃ©rente.
...
```

## ğŸ” Configuration
CrÃ©ez un fichier `.env` Ã  la racine du projet avec vos clÃ©s API :
```env
API_KEY_METEO=votre_cle_api
API_KEY_GEOCODING=votre_cle_api
```

## ğŸ‘¤ Auteur
Projet rÃ©alisÃ© dans le cadre du cours Open Data (TP2).